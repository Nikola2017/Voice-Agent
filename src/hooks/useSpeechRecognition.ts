'use client';

import { useState, useRef, useCallback, useEffect } from 'react';
import { LANGUAGES, type Language } from '@/types';

interface VoiceCommandCallbacks {
  onStop?: () => void;
  onPause?: () => void;
  onResume?: () => void;
}

interface UseSpeechRecognitionReturn {
  isRecording: boolean;
  isPaused: boolean;
  transcript: string;
  interimTranscript: string;
  recordingTime: number;
  error: string | null;
  isSupported: boolean;
  startRecording: () => void;
  stopRecording: () => string;
  pauseRecording: () => void;
  resumeRecording: () => void;
  resetTranscript: () => void;
}

// Wake word variations (how Google might hear "VelaMind")
const WAKE_WORDS = [
  'velamind', 'vela mind', 'wella mind', 'mela mind', 'bella mind',
  'vela', 'wella', 'mela', 'bella', 'vella',
  'fela mind', 'fella mind', 'fellow mind'
];

const STOP_WORDS = ['stop', 'stopp', 'beenden', 'ende', 'fertig', 'schluss'];
const PAUSE_WORDS = ['pause', 'pausieren', 'warte', 'halt'];
const RESUME_WORDS = ['weiter', 'fortsetzen', 'resume', 'continue', 'los'];

function detectCommand(text: string): 'stop' | 'pause' | 'resume' | null {
  const lower = text.toLowerCase();

  // Check if any wake word is present
  let hasWakeWord = false;
  for (const wake of WAKE_WORDS) {
    if (lower.includes(wake)) {
      hasWakeWord = true;
      break;
    }
  }

  if (!hasWakeWord) return null;

  // Check for commands
  for (const cmd of STOP_WORDS) {
    if (lower.includes(cmd)) return 'stop';
  }
  for (const cmd of PAUSE_WORDS) {
    if (lower.includes(cmd)) return 'pause';
  }
  for (const cmd of RESUME_WORDS) {
    if (lower.includes(cmd)) return 'resume';
  }

  return null;
}

function removeCommandFromText(text: string): string {
  let result = text;

  // Remove wake words and commands
  const allWords = [...WAKE_WORDS, ...STOP_WORDS, ...PAUSE_WORDS, ...RESUME_WORDS];
  for (const word of allWords) {
    const regex = new RegExp(word + '[.,!?]*\\s*', 'gi');
    result = result.replace(regex, '');
  }

  return result.trim();
}

export function useSpeechRecognition(
  language: Language,
  callbacks?: VoiceCommandCallbacks
): UseSpeechRecognitionReturn {
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [interimTranscript, setInterimTranscript] = useState('');
  const [recordingTime, setRecordingTime] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [isSupported, setIsSupported] = useState(false);

  const transcriptRef = useRef('');
  const recognitionRef = useRef<any>(null);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const isStoppingRef = useRef(false);
  const callbacksRef = useRef(callbacks);
  const commandExecutedRef = useRef(false);

  const langConfig = LANGUAGES.find(l => l.code === language);

  useEffect(() => {
    callbacksRef.current = callbacks;
  }, [callbacks]);

  useEffect(() => {
    if (typeof window !== 'undefined') {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      setIsSupported(!!SpeechRecognition);
    }
  }, []);

  const executeCommand = useCallback((command: 'stop' | 'pause' | 'resume') => {
    // Prevent double execution
    if (commandExecutedRef.current) return;
    commandExecutedRef.current = true;

    console.log('ðŸŽ¤ EXECUTING COMMAND:', command);

    if (command === 'stop' && callbacksRef.current?.onStop) {
      callbacksRef.current.onStop();
    } else if (command === 'pause' && callbacksRef.current?.onPause) {
      callbacksRef.current.onPause();
    } else if (command === 'resume' && callbacksRef.current?.onResume) {
      callbacksRef.current.onResume();
    }

    // Reset after delay
    setTimeout(() => {
      commandExecutedRef.current = false;
    }, 2000);
  }, []);

  const startRecording = useCallback(() => {
    if (!isSupported) {
      setError('Spracherkennung wird nicht unterstÃ¼tzt. Bitte Chrome oder Edge verwenden.');
      return;
    }

    if (recognitionRef.current) {
      console.log('Recognition already running');
      return;
    }

    setError(null);
    setTranscript('');
    setInterimTranscript('');
    setRecordingTime(0);
    setIsPaused(false);
    transcriptRef.current = '';
    isStoppingRef.current = false;
    commandExecutedRef.current = false;

    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    const recognition = new SpeechRecognition();

    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = langConfig?.speechCode || 'de-DE';

    recognition.onstart = () => {
      console.log('ðŸŽ™ï¸ Recording started');
      setIsRecording(true);

      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
    };

    recognition.onresult = (event: any) => {
      let final = '';
      let interim = '';

      for (let i = 0; i < event.results.length; i++) {
        const result = event.results[i];
        const text = result[0].transcript;

        if (result.isFinal) {
          // Check for command in final result
          const command = detectCommand(text);
          if (command) {
            console.log('ðŸŽ¤ Command in FINAL:', text, 'â†’', command);
            const cleanText = removeCommandFromText(text);
            if (cleanText) final += cleanText + ' ';
            executeCommand(command);
          } else {
            final += text + ' ';
          }
        } else {
          // Check for command in INTERIM result (for faster response!)
          const command = detectCommand(text);
          if (command && !commandExecutedRef.current) {
            console.log('ðŸŽ¤ Command in INTERIM:', text, 'â†’', command);
            executeCommand(command);
            // Don't add command to interim
          } else {
            interim += text;
          }
        }
      }

      if (final) {
        transcriptRef.current = final.trim();
        setTranscript(final.trim());
      }
      setInterimTranscript(interim);
    };

    recognition.onerror = (event: any) => {
      console.log('Recognition error:', event.error);
      if (event.error === 'not-allowed') {
        setError('Mikrofon-Zugriff verweigert. Bitte in Browser-Einstellungen erlauben.');
      } else if (event.error !== 'no-speech' && event.error !== 'aborted') {
        setError(`Fehler: ${event.error}`);
      }
    };

    recognition.onend = () => {
      console.log('ðŸŽ™ï¸ Recognition ended');

      if (!isStoppingRef.current && recognitionRef.current) {
        setTimeout(() => {
          try {
            if (recognitionRef.current && !isStoppingRef.current) {
              recognition.start();
            }
          } catch (e) {
            console.log('Could not restart');
          }
        }, 100);
      }
    };

    recognitionRef.current = recognition;

    try {
      recognition.start();
    } catch (e) {
      setError('Konnte Spracherkennung nicht starten.');
      recognitionRef.current = null;
    }
  }, [isSupported, langConfig, executeCommand]);

  const stopRecording = useCallback((): string => {
    console.log('ðŸ›‘ Stopping recording...');
    isStoppingRef.current = true;

    const finalTranscript = (transcriptRef.current + ' ' + interimTranscript).trim();
    // Remove any remaining command words from final transcript
    const cleanTranscript = removeCommandFromText(finalTranscript);

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {}
      recognitionRef.current = null;
    }

    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    setIsRecording(false);
    setIsPaused(false);
    setTranscript(cleanTranscript);
    setInterimTranscript('');

    console.log('ðŸ“ Final:', cleanTranscript.substring(0, 50) + '...');
    return cleanTranscript;
  }, [interimTranscript]);

  const pauseRecording = useCallback(() => {
    console.log('â¸ï¸ Pausing...');
    isStoppingRef.current = true;

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch (e) {}
    }

    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }

    setIsPaused(true);
  }, []);

  const resumeRecording = useCallback(() => {
    console.log('â–¶ï¸ Resuming...');
    setIsPaused(false);
    isStoppingRef.current = false;
    commandExecutedRef.current = false;

    if (recognitionRef.current) {
      try {
        recognitionRef.current.start();
        timerRef.current = setInterval(() => {
          setRecordingTime(prev => prev + 1);
        }, 1000);
      } catch (e) {
        console.log('Could not resume');
      }
    }
  }, []);

  const resetTranscript = useCallback(() => {
    transcriptRef.current = '';
    setTranscript('');
    setInterimTranscript('');
    setRecordingTime(0);
  }, []);

  useEffect(() => {
    return () => {
      isStoppingRef.current = true;
      if (recognitionRef.current) {
        try { recognitionRef.current.stop(); } catch (e) {}
        recognitionRef.current = null;
      }
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
    };
  }, []);

  return {
    isRecording,
    isPaused,
    transcript,
    interimTranscript,
    recordingTime,
    error,
    isSupported,
    startRecording,
    stopRecording,
    pauseRecording,
    resumeRecording,
    resetTranscript,
  };
}
